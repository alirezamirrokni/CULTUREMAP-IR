{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pp_Ceid1FbK",
        "outputId": "26f6aa1d-4272-4736-f172-3c0496f5d72b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ON_Ib1Uf8Z_o",
        "outputId": "c916489f-fd7d-4c54-eaa0-47ded64224b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting vllm\n",
            "  Downloading vllm-0.8.5-cp38-abi3-manylinux1_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from vllm) (5.5.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from vllm) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vllm) (4.67.1)\n",
            "Collecting blake3 (from vllm)\n",
            "  Downloading blake3-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from vllm) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.51.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.51.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[hf_xet]>=0.30.0->vllm) (0.30.2)\n",
            "Requirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from vllm) (5.29.4)\n",
            "Collecting fastapi>=0.115.0 (from fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from vllm) (3.11.15)\n",
            "Requirement already satisfied: openai>=1.52.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.76.0)\n",
            "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.11.3)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm) (11.2.1)\n",
            "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n",
            "  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting tiktoken>=0.6.0 (from vllm)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting lm-format-enforcer<0.11,>=0.10.11 (from vllm)\n",
            "  Downloading lm_format_enforcer-0.10.11-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting llguidance<0.8.0,>=0.7.9 (from vllm)\n",
            "  Downloading llguidance-0.7.19-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting outlines==0.1.11 (from vllm)\n",
            "  Downloading outlines-0.1.11-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting lark==1.2.2 (from vllm)\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xgrammar==0.1.18 (from vllm)\n",
            "  Downloading xgrammar-0.1.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.13.2)\n",
            "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (3.18.0)\n",
            "Collecting partial-json-parser (from vllm)\n",
            "  Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting pyzmq>=25.0.0 (from vllm)\n",
            "  Downloading pyzmq-26.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.0 kB)\n",
            "Collecting msgspec (from vllm)\n",
            "  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting gguf>=0.13.0 (from vllm)\n",
            "  Downloading gguf-0.16.2-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from vllm) (8.6.1)\n",
            "Collecting mistral_common>=1.5.4 (from mistral_common[opencv]>=1.5.4->vllm)\n",
            "  Downloading mistral_common-1.5.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.11.0.86)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from vllm) (6.0.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vllm) (0.8.1)\n",
            "Collecting compressed-tensors==0.9.3 (from vllm)\n",
            "  Downloading compressed_tensors-0.9.3-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting depyf==0.18.0 (from vllm)\n",
            "  Downloading depyf-0.18.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from vllm) (3.1.1)\n",
            "Collecting watchfiles (from vllm)\n",
            "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting python-json-logger (from vllm)\n",
            "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from vllm) (1.15.2)\n",
            "Collecting ninja (from vllm)\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting opentelemetry-sdk<1.27.0,>=1.26.0 (from vllm)\n",
            "  Downloading opentelemetry_sdk-1.26.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-api<1.27.0,>=1.26.0 (from vllm)\n",
            "  Downloading opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp<1.27.0,>=1.26.0 (from vllm)\n",
            "  Downloading opentelemetry_exporter_otlp-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions-ai<0.5.0,>=0.4.1 (from vllm)\n",
            "  Downloading opentelemetry_semantic_conventions_ai-0.4.5-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting numba==0.61.2 (from vllm)\n",
            "  Downloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting ray!=2.44.*,>=2.43.0 (from ray[cgraph]!=2.44.*,>=2.43.0->vllm)\n",
            "  Downloading ray-2.45.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio==2.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision==0.21.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.0+cu124)\n",
            "Collecting xformers==0.0.29.post2 (from vllm)\n",
            "  Downloading xformers-0.0.29.post2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting astor (from depyf==0.18.0->vllm)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting dill (from depyf==0.18.0->vllm)\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.2->vllm)\n",
            "  Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting interegular (from outlines==0.1.11->vllm)\n",
            "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (3.1.6)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (1.6.0)\n",
            "Collecting diskcache (from outlines==0.1.11->vllm)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (0.36.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (4.23.0)\n",
            "Collecting pycountry (from outlines==0.1.11->vllm)\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting airportsdata (from outlines==0.1.11->vllm)\n",
            "  Downloading airportsdata-20250224-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting outlines_core==0.1.26 (from outlines==0.1.11->vllm)\n",
            "  Downloading outlines_core-0.1.26-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->vllm) (1.3.0)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting fastapi-cli>=0.0.5 (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading fastapi_cli-0.0.7-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.28.1)\n",
            "Collecting python-multipart>=0.0.18 (from fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting uvicorn>=0.12.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.0->huggingface-hub[hf_xet]>=0.30.0->vllm) (24.2)\n",
            "Collecting hf-xet>=0.1.4 (from huggingface-hub[hf_xet]>=0.30.0->vllm)\n",
            "  Downloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (494 bytes)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (1.3.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<1.27.0,>=1.26.0->vllm) (1.2.18)\n",
            "Collecting importlib_metadata (from vllm)\n",
            "  Downloading importlib_metadata-8.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->vllm) (3.21.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc==1.26.0 (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http==1.26.0 (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.71.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading opentelemetry_proto-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf (from vllm)\n",
            "  Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting opentelemetry-semantic-conventions==0.47b0 (from opentelemetry-sdk<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (0.4.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (8.1.8)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (1.1.0)\n",
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm) (13.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2025.1.31)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.6.0->vllm) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.51.1->vllm) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.20.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<1.27.0,>=1.26.0->vllm) (1.17.2)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.15.2)\n",
            "Collecting rich-toolkit>=0.11.1 (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading rich_toolkit-0.14.4-py3-none-any.whl.metadata (999 bytes)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->outlines==0.1.11->vllm) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm) (2025.4.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm) (0.24.0)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (0.8.3)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (13.9.4)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\n",
            "Downloading vllm-0.8.5-cp38-abi3-manylinux1_x86_64.whl (326.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.4/326.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading compressed_tensors-0.9.3-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.4/98.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading depyf-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outlines-0.1.11-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.29.post2-cp311-cp311-manylinux_2_28_x86_64.whl (44.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xgrammar-0.1.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outlines_core-0.1.26-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.3/343.3 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gguf-0.16.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llguidance-0.7.19-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lm_format_enforcer-0.10.11-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mistral_common-1.5.4-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.26.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.0.0-py3-none-any.whl (24 kB)\n",
            "Downloading opentelemetry_exporter_otlp-1.26.0-py3-none-any.whl (7.0 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_http-1.26.0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_proto-1.26.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.26.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions_ai-0.4.5-py3-none-any.whl (5.5 kB)\n",
            "Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
            "Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyzmq-26.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (862 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m862.4/862.4 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.45.0-cp311-cp311-manylinux2014_x86_64.whl (68.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.4/68.4 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blake3-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (376 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.2/376.2 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl (10 kB)\n",
            "Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading fastapi_cli-0.0.7-py3-none-any.whl (10 kB)\n",
            "Downloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
            "Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading airportsdata-20250224-py3-none-any.whl (913 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m913.7/913.7 kB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading rich_toolkit-0.14.4-py3-none-any.whl (24 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: blake3, uvloop, uvicorn, pyzmq, python-multipart, python-json-logger, python-dotenv, pycountry, protobuf, partial-json-parser, opentelemetry-semantic-conventions-ai, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, msgspec, llvmlite, llguidance, lark, interegular, importlib_metadata, httptools, hf-xet, gguf, dnspython, diskcache, dill, astor, airportsdata, watchfiles, tiktoken, starlette, opentelemetry-proto, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, numba, email-validator, depyf, rich-toolkit, prometheus-fastapi-instrumentator, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, nvidia-cusolver-cu12, lm-format-enforcer, fastapi, ray, outlines_core, opentelemetry-sdk, mistral_common, fastapi-cli, xgrammar, xformers, outlines, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, compressed-tensors, opentelemetry-exporter-otlp, vllm\n",
            "  Attempting uninstall: pyzmq\n",
            "    Found existing installation: pyzmq 24.0.1\n",
            "    Uninstalling pyzmq-24.0.1:\n",
            "      Successfully uninstalled pyzmq-24.0.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "  Attempting uninstall: importlib_metadata\n",
            "    Found existing installation: importlib_metadata 8.6.1\n",
            "    Uninstalling importlib_metadata-8.6.1:\n",
            "      Successfully uninstalled importlib_metadata-8.6.1\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.32.1\n",
            "    Uninstalling opentelemetry-api-1.32.1:\n",
            "      Successfully uninstalled opentelemetry-api-1.32.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.60.0\n",
            "    Uninstalling numba-0.60.0:\n",
            "      Successfully uninstalled numba-0.60.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.53b1\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.53b1:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.53b1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.32.1\n",
            "    Uninstalling opentelemetry-sdk-1.32.1:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.32.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\n",
            "cuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\n",
            "distributed-ucxx-cu12 0.42.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "google-cloud-pubsub 2.29.0 requires opentelemetry-api>=1.27.0; python_version >= \"3.8\", but you have opentelemetry-api 1.26.0 which is incompatible.\n",
            "google-cloud-pubsub 2.29.0 requires opentelemetry-sdk>=1.27.0; python_version >= \"3.8\", but you have opentelemetry-sdk 1.26.0 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed airportsdata-20250224 astor-0.8.1 blake3-1.0.4 compressed-tensors-0.9.3 depyf-0.18.0 dill-0.4.0 diskcache-5.6.3 dnspython-2.7.0 email-validator-2.2.0 fastapi-0.115.12 fastapi-cli-0.0.7 gguf-0.16.2 hf-xet-1.1.0 httptools-0.6.4 importlib_metadata-8.0.0 interegular-0.3.3 lark-1.2.2 llguidance-0.7.19 llvmlite-0.44.0 lm-format-enforcer-0.10.11 mistral_common-1.5.4 msgspec-0.19.0 ninja-1.11.1.4 numba-0.61.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 opentelemetry-api-1.26.0 opentelemetry-exporter-otlp-1.26.0 opentelemetry-exporter-otlp-proto-common-1.26.0 opentelemetry-exporter-otlp-proto-grpc-1.26.0 opentelemetry-exporter-otlp-proto-http-1.26.0 opentelemetry-proto-1.26.0 opentelemetry-sdk-1.26.0 opentelemetry-semantic-conventions-0.47b0 opentelemetry-semantic-conventions-ai-0.4.5 outlines-0.1.11 outlines_core-0.1.26 partial-json-parser-0.2.1.1.post5 prometheus-fastapi-instrumentator-7.1.0 protobuf-4.25.7 pycountry-24.6.1 python-dotenv-1.1.0 python-json-logger-3.3.0 python-multipart-0.0.20 pyzmq-26.4.0 ray-2.45.0 rich-toolkit-0.14.4 starlette-0.46.2 tiktoken-0.9.0 uvicorn-0.34.2 uvloop-0.21.0 vllm-0.8.5 watchfiles-1.0.5 xformers-0.0.29.post2 xgrammar-0.1.18\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "f35860c411bc493d90f30012e08a9983",
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install vllm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IyLAHeew6z9J"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth vllm\n",
        "else:\n",
        "    !pip install --no-deps unsloth vllm\n",
        "    import sys, re, requests; modules = list(sys.modules.keys())\n",
        "    for x in modules: sys.modules.pop(x) if \"PIL\" in x or \"google\" in x else None\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft \"trl==0.15.2\" triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "\n",
        "    f = requests.get(\"https://raw.githubusercontent.com/vllm-project/vllm/refs/heads/main/requirements/common.txt\").content\n",
        "    with open(\"vllm_requirements.txt\", \"wb\") as file:\n",
        "        file.write(re.sub(rb\"(transformers|numpy|xformers)[^\\n]{1,}\\n\", b\"\", f))\n",
        "    !pip install -r vllm_requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "OIuZavW5k7Co"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import logging\n",
        "import time\n",
        "from pathlib import Path\n",
        "from typing import Optional, List, Dict, Any, Set\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "from rich.console import Console\n",
        "from rich.progress import Progress, SpinnerColumn, BarColumn, TextColumn, TimeElapsedColumn\n",
        "from rich.table import Table\n",
        "from PyPDF2 import PdfReader\n",
        "from unsloth import FastModel\n",
        "from unsloth.chat_templates import get_chat_template\n",
        "from rich.progress import Progress, SpinnerColumn, BarColumn, TextColumn, TimeElapsedColumn, TimeRemainingColumn\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "KU5iFS1bk9Yu"
      },
      "outputs": [],
      "source": [
        "CONFIG = {\n",
        "    \"pdf_path\": Path(os.getenv(\"PDF_PATH\", \"./books/kohgiloye.pdf\")),\n",
        "    \"province\": os.getenv(\"PROVINCE\", \"کهگیلویه‌و‌بویراحمد\"),\n",
        "    \"start_page\": int(os.getenv(\"START_PAGE\", 10)),\n",
        "    \"end_page\": 103 if os.getenv(\"END_PAGE\") in (None, \"\") else int(os.getenv(\"END_PAGE\")),\n",
        "    \"chunk_size\": int(os.getenv(\"CHUNK_SIZE\", 2000)),\n",
        "    \"overlap_size\": int(os.getenv(\"OVERLAP_SIZE\", 50)),\n",
        "    \"max_seq_length\": int(os.getenv(\"MAX_SEQ_LENGTH\", 2048)),\n",
        "    \"max_new_tokens\": int(os.getenv(\"MAX_NEW_TOKENS\", 2048)),\n",
        "    \"model_name\": os.getenv(\"MODEL_NAME\", \"unsloth/gemma-3-4b-it-unsloth-bnb-4bit\"),\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    \"log_file\": os.getenv(\"LOG_FILE\", \"extraction.log\"),\n",
        "    \"workers\": int(os.getenv(\"WORKERS\", 1)),\n",
        "    \"partial_save_interval\": int(os.getenv(\"PARTIAL_SAVE_INTERVAL\", 10))\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "MDtOzUKHlRyG"
      },
      "outputs": [],
      "source": [
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "    handlers=[\n",
        "        logging.FileHandler(CONFIG[\"log_file\"]),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "console = Console()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "_Y0rJ8B4lWhc"
      },
      "outputs": [],
      "source": [
        "def clean_json_string(s: str) -> str:\n",
        "    \"\"\"Remove JavaScript‐style comments and stray commas so the JSON can be parsed reliably.\"\"\"\n",
        "    s = re.sub(r\"//.*\", \"\", s)\n",
        "    s = re.sub(r\"/\\*.*?\\*/\", \"\", s, flags=re.DOTALL)\n",
        "    s = re.sub(r\",(\\s*[}\\]])\", r\"\\1\", s)\n",
        "    return s\n",
        "\n",
        "\n",
        "def extract_json_block(text: str) -> str | None:\n",
        "    \"\"\"Scan through a string of mixed content and return the longest balanced `{…}` JSON snippet, or None if none found.\"\"\"\n",
        "    blocks = []\n",
        "    start = None\n",
        "    depth = 0\n",
        "    for i, ch in enumerate(text):\n",
        "        if ch == '{':\n",
        "            if depth == 0:\n",
        "                start = i\n",
        "            depth += 1\n",
        "        elif ch == '}' and depth > 0:\n",
        "            depth -= 1\n",
        "            if depth == 0 and start is not None:\n",
        "                blocks.append(text[start : i + 1])\n",
        "                start = None\n",
        "    if not blocks:\n",
        "        return None\n",
        "    return max(blocks, key=len)\n",
        "\n",
        "\n",
        "def clean_json_block(raw: str) -> str:\n",
        "    \"\"\"Strip out any Markdown-style code fences (```…```) from around a raw JSON block.\"\"\"\n",
        "    s = raw.strip()\n",
        "    if s.startswith(\"```\"):\n",
        "        lines = s.splitlines()\n",
        "        if lines[0].startswith(\"```\"):\n",
        "            lines = lines[1:]\n",
        "        if lines and lines[-1].startswith(\"```\"):\n",
        "            lines = lines[:-1]\n",
        "        s = \"\\n\".join(lines)\n",
        "    return s\n",
        "\n",
        "\n",
        "def extract_text_from_pdf(path: Path, start: int, end: Optional[int]) -> str:\n",
        "    \"\"\"Read text from pages `start` through `end` of a PDF file and concatenate them into one string.\"\"\"\n",
        "    reader = PdfReader(str(path))\n",
        "    pages = reader.pages[start-1 : end] if end else reader.pages[start-1 :]\n",
        "    texts = []\n",
        "    for page in pages:\n",
        "        try:\n",
        "            texts.append(page.extract_text() or \"\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Failed to extract page text: {e}\")\n",
        "    return \"\\n\".join(texts)\n",
        "\n",
        "\n",
        "def normalize_text(text: str) -> str:\n",
        "    \"\"\"Collapse all whitespace into single spaces and strip out any digits.\"\"\"\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def chunk_text(text: str, max_chars: int, overlap: int) -> List[str]:\n",
        "    \"\"\"Break `text` into word‐aligned chunks up to `max_chars` long, preserving an `overlap` of characters for context.\"\"\"\n",
        "    words = text.split()\n",
        "    if not words:\n",
        "        return []\n",
        "\n",
        "    chunks: List[str] = []\n",
        "    current: List[str] = []\n",
        "    length = 0\n",
        "\n",
        "    for w in words:\n",
        "        if length + len(w) + 1 > max_chars:\n",
        "            chunk = \" \".join(current)\n",
        "            chunks.append(chunk)\n",
        "            if overlap > 0 and len(chunk) > overlap:\n",
        "                carry = chunk[-overlap:]\n",
        "                current = carry.split()\n",
        "                length = sum(len(x) + 1 for x in current)\n",
        "            else:\n",
        "                current = []\n",
        "                length = 0\n",
        "        current.append(w)\n",
        "        length += len(w) + 1\n",
        "\n",
        "    if current:\n",
        "        chunks.append(\" \".join(current))\n",
        "\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "3_x9MjBTla6N"
      },
      "outputs": [],
      "source": [
        "JSON_SCHEMA_EXACT = \"\"\"\n",
        "نمونه ساختار دقیق JSON برای هر استان:\n",
        "\n",
        "{{\n",
        "  \"title\": \"string\",\n",
        "  \"location\": {{ \"province\":\"string\",\"city\":\"string\" }},\n",
        "  \"geographical_features\":[\n",
        "    {{ \"name\":\"string\",\"items\":[{{ \"name\":\"string\",\"images\":[\"string\"] }}]}}\n",
        "  ],\n",
        "  \"natural_resources\":[\n",
        "    {{ \"name\":\"string\",\"description\":[\"string\"] }}\n",
        "  ],\n",
        "  \"vegetation\":[\"string\"],\n",
        "  \"topography\":[\n",
        "    {{ \"name\":\"string\",\"description\":[\"string\"] }}\n",
        "  ],\n",
        "  \"tourist_attractions\":[\n",
        "    {{ \"name\":\"string\",\"images\":[\"string\"],\"year_built\":\"string\",\n",
        "       \"constructor\":\"string\",\"architect\":\"string\",\"description\":\"string\" }}\n",
        "  ],\n",
        "  \"climate_impacts\":[\n",
        "    {{ \"impact\":\"string\",\"description\":[\"string\"] }}\n",
        "  ],\n",
        "  \"additional_info\":{{\n",
        "    \"books_source\":\"string\",\"other_sources\":[\"string\"]\n",
        "  }}\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "EXAMPLE_JSON = \"\"\"\n",
        "مثال پرشده برای «ویژگی‌های جغرافیایی کهگیلویه‌و‌بویراحمد:\n",
        "\n",
        "{{\n",
        "  \"title\": \"ویژگی‌های جغرافیایی کهگیلویه‌و‌بویراحمد\",\n",
        "  \"location\": {{ \"province\":\"کهگیلویه‌و‌بویراحمد\",\"city\":\"یاسوج\" }},\n",
        "  \"geographical_features\":[\n",
        "    {{\n",
        "      \"name\": \"رودخانه‌ها\",\n",
        "      \"items\":[{{ \"name\":\"رود مارون\",\"images\": [] }}]\n",
        "    }},\n",
        "    {{\n",
        "      \"name\": \"کوه‌ها\",\n",
        "      \"items\":[{{ \"name\":\"کوه سرخ\",\"images\": [] }}]\n",
        "    }}\n",
        "  ],\n",
        "  \"natural_resources\": [],\n",
        "  \"vegetation\": [],\n",
        "  \"topography\": [],\n",
        "  \"tourist_attractions\": [],\n",
        "  \"climate_impacts\": [],\n",
        "  \"additional_info\": {{ \"books_source\":\"\",\"other_sources\":[] }}\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "شما مدل Gemma-3 هستید و **تنها** باید یک شیء JSON یکتا و **معتبر** تولید کنید.\n",
        "۱. کلیدها و مقدارهای رشته‌ای حتماً با گیومهٔ دوگانه (\"\") باشند.\n",
        "۲. اگر داده‌ای وجود ندارد، از \"\" یا [] استفاده کنید؛ **هرگز** {{}} خالی ننویسید.\n",
        "۳. اگر برای فیلدی اطمینان کمتر از ۹۰٪ دارید یا داده نیست، آن را \"\" یا [] بگذارید.\n",
        "۴. حتماً حداقل یک مورد واقعی برای هر لیست استخراج‌شده در متن بیاورید.\n",
        "۵. **هرگز** JSON را داخل code fence (```…```) یا تگ Markdown قرار ندهید—فقط جسم خالص JSON را برگردانید!\n",
        "۶. فقط JSON خالص، بدون توضیح یا کامنت.\n",
        "۷. **هرگز** تنها مجموعهٔ نمونه (EXAMPLE_JSON) را به‌عنوان خروجی نهایی برنگردانید؛ حتماً داده‌های استخراج‌شده از متن ورودی را نمایش دهید.\n",
        "\n",
        "{schema}\n",
        "\n",
        "{example}\n",
        "\n",
        "حال با متن زیر، دقیقاً یک شیء JSON منطبق بر ساختار فوق برگردانید:\n",
        "\"\"\"\n",
        "\n",
        "def build_prompt(province: str, chunk: str) -> str:\n",
        "    \"\"\"\n",
        "    Construct the model’s input prompt for a given province and text chunk.\n",
        "\n",
        "    This will insert the exact JSON schema and example into the template,\n",
        "    then append the source text under a clear ‘متن منبع’ header so the model\n",
        "    knows exactly what to parse and where the data applies.\n",
        "\n",
        "    :param province: The name of the province to contextualize the prompt.\n",
        "    :param chunk: The segment of source text to include.\n",
        "    :return: A ready-to-send prompt string combining template, example, and text.\n",
        "    \"\"\"\n",
        "    return (\n",
        "        PROMPT_TEMPLATE.format(\n",
        "            province=province,\n",
        "            schema=JSON_SCHEMA_EXACT,\n",
        "            example=EXAMPLE_JSON,\n",
        "        )\n",
        "        + \"\\n--- متن منبع ---\\n\"\n",
        "        + chunk\n",
        "        + \"\\n\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "N-0CiKoblewt",
        "outputId": "e6cb77a1-5a41-4a6e-b494-0edc2b8c8b9f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[17:58:32] </span>Loading model unsloth/gemma-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>-4b-it-unsloth-bnb-4bit on cuda<span style=\"color: #808000; text-decoration-color: #808000\">...</span>        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-37-c3609df2e89d&gt;:1</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[17:58:32]\u001b[0m\u001b[2;36m \u001b[0mLoading model unsloth/gemma-\u001b[1;36m3\u001b[0m-4b-it-unsloth-bnb-4bit on cuda\u001b[33m...\u001b[0m        \u001b[2m<ipython-input-37-c3609df2e89d>:1\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.4.4: Fast Gemma3 patching. Transformers: 4.51.3. vLLM: 0.8.5.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: Using float16 precision for gemma3 won't work! Using float32.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[17:58:52] </span>Model loaded Succesfully!                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-37-c3609df2e89d&gt;:11</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[17:58:52]\u001b[0m\u001b[2;36m \u001b[0mModel loaded Succesfully!                                             \u001b[2m<ipython-input-37-c3609df2e89d>:11\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "console.log(f\"Loading model {CONFIG['model_name']} on {CONFIG['device']}...\")\n",
        "model, tokenizer = FastModel.from_pretrained(\n",
        "    model_name=CONFIG['model_name'],\n",
        "    max_seq_length=CONFIG['max_seq_length'],\n",
        "    load_in_4bit=True,\n",
        "    load_in_8bit=False,\n",
        "    full_finetuning=False,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "tokenizer = get_chat_template(tokenizer, chat_template=\"gemma-3\")\n",
        "console.log(\"Model loaded Succesfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "x1eaYl2-lyY5"
      },
      "outputs": [],
      "source": [
        "seen_entries = {\n",
        "    \"geographical_features\": set(),\n",
        "    \"natural_resources\": set(),\n",
        "    \"vegetation\": set(),\n",
        "    \"topography\": set(),\n",
        "    \"tourist_attractions\": set(),\n",
        "    \"climate_impacts\": set(),\n",
        "}\n",
        "seen_subitems = set()\n",
        "\n",
        "def process_chunk(chunk: str, idx: int) -> Optional[Dict[str, Any]]:\n",
        "    prompt = build_prompt(CONFIG['province'], chunk)\n",
        "    if idx <= 10:\n",
        "        console.rule(f\"[bold green]Chunk {idx} Prompt[/]\")\n",
        "        console.print(prompt, overflow=\"fold\")\n",
        "        console.rule()\n",
        "\n",
        "    inp = tokenizer.apply_chat_template(\n",
        "        [{\"role\":\"user\",\"content\":[{\"type\":\"text\",\"text\":prompt}]}],\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "    inputs = tokenizer([inp], return_tensors=\"pt\").to(CONFIG['device'])\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=512,\n",
        "            temperature=1.0,\n",
        "            top_p=0.9,\n",
        "            top_k=50,\n",
        "        )\n",
        "    decoded = tokenizer.batch_decode(out)[0]\n",
        "\n",
        "    marker = \"<start_of_turn>model\"\n",
        "    content = decoded.split(marker,1)[1] if marker in decoded else decoded\n",
        "    content = content.replace(\"<end_of_turn>\", \"\").strip()\n",
        "\n",
        "    if idx <= 10:\n",
        "        console.rule(f\"[bold blue]Chunk {idx} Raw Output[/]\")\n",
        "        console.print(content, overflow=\"fold\")\n",
        "        console.rule()\n",
        "\n",
        "    raw_json = extract_json_block(content)\n",
        "    if not raw_json:\n",
        "        console.log(f\"[red]⚠️ Chunk {idx}: no JSON block. Snippet: {content[:200]}...\")\n",
        "        cleanup_gpu(inputs, out)\n",
        "        return None\n",
        "\n",
        "    raw_json = clean_json_block(raw_json)\n",
        "    raw_json = clean_json_string(raw_json)\n",
        "\n",
        "    if idx <= 10:\n",
        "        console.rule(f\"[bold yellow]Chunk {idx} Extracted JSON Block[/]\")\n",
        "        console.print(raw_json, overflow=\"fold\")\n",
        "        console.rule()\n",
        "\n",
        "    try:\n",
        "        parsed = json.loads(raw_json)\n",
        "    except json.JSONDecodeError as e:\n",
        "        console.log(f\"[red]Chunk {idx} JSON parse error:[/] {e}\")\n",
        "        parsed = None\n",
        "\n",
        "    if parsed:\n",
        "        for section in [\"geographical_features\",\"natural_resources\",\"topography\",\n",
        "                        \"tourist_attractions\",\"climate_impacts\"]:\n",
        "            new_list = []\n",
        "            for item in parsed.get(section, []):\n",
        "                name = item.get(\"name\")\n",
        "                if not name or name in seen_entries[section]:\n",
        "                    continue\n",
        "                seen_entries[section].add(name)\n",
        "\n",
        "                if section == \"geographical_features\":\n",
        "                    kept_subs = []\n",
        "                    for sub in item.get(\"items\", []):\n",
        "                        subname = sub.get(\"name\")\n",
        "                        if subname and subname not in seen_subitems:\n",
        "                            seen_subitems.add(subname)\n",
        "                            kept_subs.append(sub)\n",
        "                    item[\"items\"] = kept_subs\n",
        "                    if kept_subs:\n",
        "                        new_list.append(item)\n",
        "                else:\n",
        "                    new_list.append(item)\n",
        "            parsed[section] = new_list\n",
        "\n",
        "        for section in [\"vegetation\"]:\n",
        "            new_list = []\n",
        "            for val in parsed.get(section, []):\n",
        "                if not val:\n",
        "                    continue\n",
        "                val_key = json.dumps(val, sort_keys=True)\n",
        "                if val_key not in seen_entries[section]:\n",
        "                    seen_entries[section].add(val_key)\n",
        "                    new_list.append(val)\n",
        "            parsed[section] = new_list\n",
        "\n",
        "    if idx <= 10 and parsed is not None:\n",
        "        console.rule(f\"[bold magenta]Chunk {idx} Parsed & Deduped JSON[/]\")\n",
        "        console.print(json.dumps(parsed, ensure_ascii=False, indent=2))\n",
        "        console.rule()\n",
        "\n",
        "    cleanup_gpu(inputs, out)\n",
        "    return parsed\n",
        "\n",
        "def cleanup_gpu(inputs, out):\n",
        "    \"\"\"Helper to free GPU memory immediately.\"\"\"\n",
        "    import gc\n",
        "    del inputs, out\n",
        "    gc.collect()\n",
        "    if CONFIG['device'].startswith(\"cuda\"):\n",
        "        torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "NEYL5PXm0wvy"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    \"\"\"\n",
        "    Orchestrate the end-to-end extraction for a given province:\n",
        "      1. Load and normalize text from the configured PDF pages.\n",
        "      2. Split that text into overlapping chunks.\n",
        "      3. Send each chunk to the model, filtering out any duplicate entries.\n",
        "      4. Aggregate all unique results into one JSON file.\n",
        "      5. Display progress during processing and a summary table at the end.\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    console.rule(\"[bold green]Starting Province Extraction[/]\")\n",
        "\n",
        "    text = extract_text_from_pdf(CONFIG['pdf_path'], CONFIG['start_page'], CONFIG['end_page'])\n",
        "    text = normalize_text(text)\n",
        "    chunks = chunk_text(text, CONFIG['chunk_size'], CONFIG['overlap_size'])\n",
        "\n",
        "    console.print(f\"[bold]Province:[/] {CONFIG['province']}\")\n",
        "    console.print(f\"[bold]Total chunks to process:[/] {len(chunks)}\\n\")\n",
        "\n",
        "    combined: Dict[str, Any] = {\"province\": CONFIG['province']}\n",
        "    partials: List[Dict[str, Any]] = []\n",
        "\n",
        "    with Progress(\n",
        "        SpinnerColumn(style=\"bold green\"),\n",
        "        TextColumn(\"[progress.description]{task.description}\"),\n",
        "        BarColumn(bar_width=None),\n",
        "        TextColumn(\"[bold magenta]{task.completed}/{task.total} chunks\"),\n",
        "        TimeElapsedColumn(),\n",
        "        TimeRemainingColumn(),\n",
        "        console=console\n",
        "    ) as progress:\n",
        "        task_id = progress.add_task(\"Extracting chunks\", total=len(chunks))\n",
        "        for idx, chunk in enumerate(chunks, start=1):\n",
        "            result = process_chunk(chunk, idx)\n",
        "            if result:\n",
        "                partials.append(result)\n",
        "            progress.advance(task_id)\n",
        "\n",
        "    for part in partials:\n",
        "        for key, value in part.items():\n",
        "            if key == \"province\":\n",
        "                continue\n",
        "            if key not in combined:\n",
        "                combined[key] = value\n",
        "            elif isinstance(value, list) and isinstance(combined[key], list):\n",
        "                combined[key].extend(value)\n",
        "\n",
        "    out_path = Path(f\"./{CONFIG['province']}_dataset.json\")\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(combined, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    total_items = sum(\n",
        "        len(v) if isinstance(v, list) else 1\n",
        "        for k, v in combined.items()\n",
        "        if k != \"province\"\n",
        "    )\n",
        "\n",
        "    console.rule(\"[bold green]Extraction Complete[/]\")\n",
        "    console.print(f\"• Saved to: [bold]{out_path}[/]\")\n",
        "    console.print(f\"• Items extracted: [bold]{total_items}[/]\")\n",
        "    console.print(f\"• Chunks processed: [bold]{len(chunks)}[/]\")\n",
        "    console.print(f\"• Elapsed time: [bold]{elapsed:.2f}s[/]\\n\")\n",
        "\n",
        "    table = Table(title=\"✅ Extraction Summary\")\n",
        "    table.add_column(\"Province\", style=\"cyan\")\n",
        "    table.add_column(\"Items\", justify=\"right\", style=\"magenta\")\n",
        "    table.add_column(\"Chunks\", justify=\"right\", style=\"magenta\")\n",
        "    table.add_column(\"Time (s)\", justify=\"right\", style=\"magenta\")\n",
        "    table.add_row(\n",
        "        CONFIG[\"province\"],\n",
        "        str(total_items),\n",
        "        str(len(chunks)),\n",
        "        f\"{elapsed:.2f}\"\n",
        "    )\n",
        "    console.print(table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "302cf2d3357249eba3de0db3b40e51c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "381b63b4d6b74c0ebbec72cc81548b4a": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_302cf2d3357249eba3de0db3b40e51c2",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">⠏</span> Extracting chunks <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">31/44 chunks</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:20:15</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n</pre>\n",
                  "text/plain": "\u001b[1;32m⠏\u001b[0m Extracting chunks \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1;35m31/44 chunks\u001b[0m \u001b[33m0:20:15\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
